{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ahmetyldrr/Large-Language-Models-LLMs-/blob/main/Chapter8_AI_Alignment_First_Principles.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "source  :  https://learning.oreilly.com/videos/quick-start-guide/9780135384800/9780135384800-QGL2_02_08_00/"
      ],
      "metadata": {
        "id": "0T0CdySye191"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Görüntüdeki Konunun Özeti (Hizalama / Alignment)\n",
        "\n",
        "Paylaşılan görselde, büyük dil modellerinin (örneğin GPT-3 gibi) **hizalanması** (*alignment*) konusu anlatılıyor. Burada \"hizalama\", bir yapay zekâ modelinin ürettiği cevapların insan beklentileriyle ve istenen etik/yararlı çerçeveyle uyuşmasını sağlamayı ifade eder.\n",
        "\n",
        "## Örnek Durum: \"Dünya düz müdür?\"\n",
        "\n",
        "- **Hizalamadan önce**: Model, \"Dünya düzdür, ufuk bu yüzden...\" gibi yanlış bilgiler içeren bir cevap verebilir. Bu, ham veriyle eğitilmiş ancak ince ayar yapılmamış modelin, doğru bilgi ile yanlış bilgi arasındaki farkı ayırt etme konusunda eksik kaldığını gösterir.\n",
        "- **Hizalamadan sonra**: Aynı soru sorulduğunda, model \"Hayır, Dünya düzdür demek doğru değil, aslında Dünya küreseldir...\" gibi daha tutarlı ve doğru bir cevap verir. Bu, modelin insan geribildirimi ve ek yöntemlerle hizalanmış olduğunu gösterir.\n",
        "\n",
        "---\n",
        "\n",
        "## Hizalama (Alignment) Nedir?\n",
        "\n",
        "Hizalama, modelin çıktılarının:\n",
        "\n",
        "- Yanlış veya zararlı bilgiler üretmemesi,\n",
        "- Kullanıcının sorusuna uygun, anlaşılır ve istenen formatta yanıt vermesi,\n",
        "- Etik ve güvenli çerçevelere sadık kalması,\n",
        "- Saldırgan, nefret söylemi içeren veya tehlikeli içeriklerden kaçınması\n",
        "\n",
        "sağlanması için yapılan düzenlemeler bütünüdür.\n",
        "\n",
        "### Nasıl Yapılır?\n",
        "\n",
        "- **İnsan Geribildirimi (Human Feedback)**: Modelin cevapları, insan değerlendiriciler tarafından incelenir. Hangi cevapların doğru veya yanlış olduğu belirlenir.\n",
        "- **Reinforcement Learning from Human Feedback (RLHF)**: İnsan geribildirimi, pekiştirmeli öğrenme yöntemleriyle kullanılarak modelin ödül mekanizması oluşturulur.\n",
        "- **İnce Ayar (Fine-tuning)**: Temel eğitimi yapılmış model, daha küçük veri setleri üzerinde \"nasıl cevap vermesi gerektiği\" öğretilerek yeniden eğitilir.\n",
        "\n",
        "---\n",
        "\n",
        "## Neden Kullanılır?\n",
        "\n",
        "1. **Doğruluk ve Güvenilirlik**: Modelin, temel eğitim sonrasında rastgele yanıtlar yerine doğrulara dayalı cevaplar vermesi sağlanır.\n",
        "2. **Zararlı İçerik Kontrolü**: Modelin, nefret söylemi, ayrımcılık veya tehlikeli içerikler üretmemesi için önlemler alınır.\n",
        "3. **Kullanıcı Deneyimi**: Kullanıcıların sorularına uygun ve anlaşılır yanıtlar vererek deneyimi iyileştirilir.\n",
        "4. **Etik ve Yasal Sorumluluklar**: Modellerin çıkardığı içeriklerden yasal ve etik sorumlulukların doğmaması için modelin belirli ilkelere göre sınırlandırılması hedeflenir.\n",
        "\n",
        "---\n",
        "\n",
        "## Özetle\n",
        "\n",
        "- **Hizalama**: LLM’lerin (büyük dil modelleri) çıktılarının doğru, güvenilir ve etik değerlere uygun hale getirilmesi sürecidir.\n",
        "- Bu süreç sayesinde, model \"Dünya düz müdür?\" gibi temel sorularda bile yanlış bilgiyi tekrarlamadan, doğru ve güvenilir bilgiler sunar.\n",
        "- Hizalama, hem kullanıcı deneyimini iyileştirir hem de zararlı içeriklerin önüne geçilmesine yardımcı olur.\n",
        "\n",
        "Dolayısıyla, hizalama süreci modeli daha güvenilir, faydalı ve doğru yanıtlar üreten bir yardımcı hâline getirirken, toplumun genel etik değerleriyle uyumlu bir yapay zekâ sistemi oluşturmayı amaçlar.\n"
      ],
      "metadata": {
        "id": "ITDCVuDuRhaE"
      }
    }
  ]
}