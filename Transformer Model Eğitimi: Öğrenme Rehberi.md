
# ğŸš€ Kendi Verinle Transformer Model EÄŸitimi: Ã–ÄŸrenme Rehberi

Bu rehber, **kendi verinle, kendi etiketlerinle** bir Transformer (Ã¶rnek: BERT) modelini nasÄ±l eÄŸiteceÄŸini adÄ±m adÄ±m aÃ§Ä±klar. Ã–ÄŸrenme sÃ¼recini hÄ±zlandÄ±rmak ve sorularÄ±nÄ± cevaplamak iÃ§in hazÄ±rlanmÄ±ÅŸtÄ±r.

---

## ğŸ¯ AmaÃ§

> **Kendi metin verim** + **kendi etiketlerim** = **Ã¶zelleÅŸtirilmiÅŸ sÄ±nÄ±flandÄ±rma modeli**

Ã–rneÄŸin:
- Duygu analizi (pozitif / negatif / nÃ¶tr)
- Konu sÄ±nÄ±flandÄ±rma (spor / politika / magazin)
- Åikayet tespiti (Ã¼rÃ¼n / teslimat / hizmet)

---

## ğŸ”¹ Veri YapÄ±sÄ± NasÄ±l OlmalÄ±?

Verin `.csv` dosyasÄ±nda ÅŸu ÅŸekilde olabilir:

| text                                | label     |
|-------------------------------------|-----------|
| â€œKargo geÃ§ geldi ama Ã¼rÃ¼n gÃ¼zeldiâ€  | teslimat  |
| â€œTelefon 1 hafta iÃ§inde bozuldu.â€   | Ã¼rÃ¼n      |
| â€œMÃ¼ÅŸteri hizmetleri Ã§ok iyiydi.â€    | hizmet    |

Etiketler senin seÃ§imine gÃ¶re deÄŸiÅŸebilir.

---

## ğŸ”¸ 1. Gerekli KÃ¼tÃ¼phaneler

```bash
pip install transformers datasets pandas scikit-learn
```

---

## ğŸ”¸ 2. CSV Verisini YÃ¼kle

```python
import pandas as pd
from datasets import Dataset

df = pd.read_csv("verin.csv")  # kendi dosya adÄ±nÄ± koy
dataset = Dataset.from_pandas(df)
```

---

## ğŸ”¸ 3. Tokenizer ve Model Kurulumu

```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification

model_ckpt = "bert-base-uncased"  # TÃ¼rkÃ§e ise: dbmdz/bert-base-turkish-cased
tokenizer = AutoTokenizer.from_pretrained(model_ckpt)

labels = list(set(df['label']))
label2id = {label: i for i, label in enumerate(labels)}
id2label = {i: label for label, i in label2id.items()}

def tokenize(example):
    return tokenizer(example['text'], truncation=True, padding='max_length')

dataset = dataset.map(tokenize)
dataset = dataset.rename_column("label", "labels")
dataset = dataset.class_encode_column("labels")

model = AutoModelForSequenceClassification.from_pretrained(
    model_ckpt,
    num_labels=len(labels),
    id2label=id2label,
    label2id=label2id
)
```

---

## ğŸ”¸ 4. EÄŸitim AyarlarÄ±

```python
from transformers import TrainingArguments, Trainer

args = TrainingArguments(
    output_dir="./model-out",
    per_device_train_batch_size=16,
    num_train_epochs=3,
    evaluation_strategy="no",
    save_strategy="epoch"
)

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=dataset
)

trainer.train()
```

---

## ğŸ”¸ 5. Tahmin Yapmak

```python
text = "Telefonun ÅŸarjÄ± Ã§ok Ã§abuk bitiyor."
inputs = tokenizer(text, return_tensors="pt")
outputs = model(**inputs)
predicted_id = outputs.logits.argmax(dim=-1).item()
print("Tahmin:", id2label[predicted_id])
```

---

## â“ SÄ±k Sorular & Cevaplar

### ğŸ“Œ Verim TÃ¼rkÃ§e, ne yapmalÄ±yÄ±m?
â†’ Model olarak `dbmdz/bert-base-turkish-cased` kullan.

### ğŸ“Œ CSVâ€™yi nasÄ±l oluÅŸturmalÄ±yÄ±m?
â†’ `text` ve `label` baÅŸlÄ±klÄ± 2 sÃ¼tun yeterlidir.

### ğŸ“Œ Etiket sayÄ±sÄ± 10â€™dan fazlaysa?
â†’ `num_labels` otomatik ayarlanÄ±r, sÄ±nÄ±r yok.

### ğŸ“Œ KÃ¼Ã§Ã¼k model istiyorum?
â†’ `distilbert-base-uncased` gibi modeller kullanabilirsin.

---

## ğŸ”— FaydalÄ± Linkler

- [Hugging Face Turkish Models](https://huggingface.co/models?language=tr&search=bert)
- [Datasets Belgeleri](https://huggingface.co/docs/datasets/)
- [Transformers Belgeleri](https://huggingface.co/docs/transformers/)
- [YouTube: TÃ¼rkÃ§e BERT EÄŸitimi](https://www.youtube.com/watch?v=3M8xL3xKJ2I)

---

**HazÄ±rlayan:** Santiago Delgado (Santi)  
**AmacÄ±:** Ã–ÄŸrenmeni hÄ±zlandÄ±rmak ve sana Ã¶zel proje oluÅŸturmanÄ± kolaylaÅŸtÄ±rmak âœ¨
